{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection - Transfer Learning with PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOEThYjzfTi/BaBLNqtuOeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenjkaplan/snow-grooming-object-detection/blob/master/Object_Detection_Transfer_Learning_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C76rGFrDCWP",
        "colab_type": "text"
      },
      "source": [
        "# Object Detection - Transfer Learning with PyTorch\n",
        "\n",
        "This notebook can be used generally to fine tune a Faster R-CNN model with custom images/annotations in PyTorch to perform object detection on a domain specific task. \n",
        "\n",
        "It was initially written to perform this task and apply the model to video footage of ski resorts to serve as a proof of concept for autonomous snow grooming vehicles. More info [here](https://github.com/stephenjkaplan/snow-grooming-object-detection).\n",
        "\n",
        "\n",
        "Stephen Kaplan, 9-16-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H_w-q1VQIWf",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDcLa0OXeair",
        "colab_type": "text"
      },
      "source": [
        "### Download additional utility files.\n",
        "\n",
        "**Torchvision**\n",
        "\n",
        "Clones functionality form the `torchvision` library not directly accessible through a normal `pip install` command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c1htRqPAWB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrFKGa3fQosj",
        "colab_type": "text"
      },
      "source": [
        "**Clone full repository containing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t27HVa7ocK3",
        "colab_type": "text"
      },
      "source": [
        "### Global Variables\n",
        "\n",
        "**Detectable Objects**\n",
        "\n",
        "Define list of objects you plan to detect. These must match the data \n",
        "downloaded in the data acquisition step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI6AxLVajh6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj_class_labels = ['tree', 'person', 'street light']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArUJwMlAFSQK",
        "colab_type": "text"
      },
      "source": [
        "**Current Working Directory**\n",
        "\n",
        "Specify current working directory. If you are working in Google Colab, you should follow a similar convention as the example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3RSV7bE-RCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = '/content/drive/My Drive/Colab Notebooks/snow_grooming/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehYEE6StDVlL",
        "colab_type": "text"
      },
      "source": [
        "### Imports \n",
        "\n",
        "Import library, and mount Google Drive. If not using a Google Colab notebook, you should Comment the relevant code out. *Tip: Manually copy and paste the verification code that Google provides when mounting the Drive. Using the copy button doesn't seem to work well.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kql8NI9716Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from ytdownloader.downloader import Downloader\n",
        "\n",
        "import cv2\n",
        "import utils\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# custom modules\n",
        "import sys\n",
        "root_dir = '/content/drive/My Drive/Colab Notebooks/snow_grooming/'\n",
        "sys.path.append(root_dir)\n",
        "\n",
        "from utilities import train_model, evaluate\n",
        "from \n",
        "from dataset import GoogleOpenImageDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNgWBcXyLrTa",
        "colab_type": "text"
      },
      "source": [
        "### Set Device\n",
        "Sets to CPU if GPU not available. In order to enable GPU in Google Colab, \n",
        "select `Runtime` --> `Change runtime type` and select `GPU` for `Hardware accelerator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRDvEXG5XXug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2NzlLD4Ntt8",
        "colab_type": "text"
      },
      "source": [
        "## Data Acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpSO9QYRN9li",
        "colab_type": "text"
      },
      "source": [
        "### Download data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyPR4xU0p4td",
        "colab_type": "text"
      },
      "source": [
        "### Explore data format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9aFouMMmwOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = GoogleOpenImageDataset(root_dir, obj_class_labels, max_images_per_class=5000, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrNQrhBxfdYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset[40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhgsaHUOKcry",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection\n",
        "\n",
        "*Note: I would have preferred to do K-Folds Cross Validation while selecting the model, but iteration was too slow given the time constraints of the project. I chose to just use one training and validation set, but recognize that isn't an optimal strategy for hyperparameter selection.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THS1vXqUjcQc",
        "colab_type": "text"
      },
      "source": [
        "##### Create training / validation / test dataset splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDllrnN_rZRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 2 versions of the dataset. one used for training \n",
        "dataset_train = GoogleOpenImageDataset(root_dir, obj_class_labels, max_images_per_class=5000, train=True)\n",
        "dataset_train_val = GoogleOpenImageDataset(root_dir, obj_class_labels, max_images_per_class=5000, train=True)\n",
        "dataset_val = GoogleOpenImageDataset(root_dir, obj_class_labels, max_images_per_class=5000)\n",
        "dataset_test = GoogleOpenImageDataset(root_dir, obj_class_labels, max_images_per_class=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9qE_4PlBJF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_size = len(dataset_test)\n",
        "\n",
        "# for trainval/test split\n",
        "train_val_percent = 0.80\n",
        "test_percent = 0.20\n",
        "train_val_size = int(train_val_percent*total_size)\n",
        "test_size = total_size - train_val_size\n",
        "splits_1 = [train_val_size, test_size]\n",
        "\n",
        "# for train/val split\n",
        "train_percent = 0.80\n",
        "val_percent = 0.20\n",
        "train_size = int(train_percent*train_val_size)\n",
        "val_size = train_val_size - train_size\n",
        "splits_2 = [train_size, val_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HOYpkLCWiv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset in train, val and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(total_size).tolist()\n",
        "\n",
        "train_val_idx, test_idx = torch.utils.data.random_split(indices, splits_1)\n",
        "train_idx, val_idx = torch.utils.data.random_split(train_val_idx, splits_2)\n",
        "\n",
        "# make subsets based on train/val/test splits\n",
        "dataset_train_val = torch.utils.data.Subset(dataset_train_val, train_val_idx)\n",
        "dataset_train = torch.utils.data.Subset(dataset_train, train_idx)\n",
        "dataset_val = torch.utils.data.Subset(dataset_val, val_idx)\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, test_idx)\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader_train_val = torch.utils.data.DataLoader(\n",
        "    dataset_train_val, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_val = torch.utils.data.DataLoader(\n",
        "    dataset_val, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N67F7lgzJsFs",
        "colab_type": "text"
      },
      "source": [
        "##### Define hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bcw_z5UJyw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "\n",
        "# learning rate schedule\n",
        "step_size = 3   # learning rate will step every __ epochs\n",
        "gamma = 0.1    # learning rate will be multiplied by gamma every step \n",
        "\n",
        "num_epochs = 10\n",
        "trainable_layers = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f09Au6TynJiA",
        "colab_type": "text"
      },
      "source": [
        "##### Train Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcRxEpw-Atq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(obj_class_labels, trainable_layers, device, learning_rate, momentum, \n",
        "            weight_decay, step_size, gamma, num_epochs, data_loader_train, \n",
        "            data_loader_val=data_loader_val, score_val=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OosvL0isoTD0",
        "colab_type": "text"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq30kOyOoWku",
        "colab_type": "text"
      },
      "source": [
        "#### Train Neural Network\n",
        "Train final model with ALL training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5RUYXg7ogG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train_model(obj_class_labels, trainable_layers, device, learning_rate, momentum, \n",
        "                    weight_decay, step_size, gamma, num_epochs=5, \n",
        "                    data_loader_train=data_loader_train_val, data_loader_val=data_loader_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UWY0wvBoghx",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1cYsZv7omno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(model, data_loader_test, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omg_Untbnceo",
        "colab_type": "text"
      },
      "source": [
        "#### Persist model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-sw2qvCgBdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('models'):\n",
        "    os.mkdir('models')\n",
        "\n",
        "torch.save(model, f'{root_dir}models/final_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft7ylEUJnsBF",
        "colab_type": "text"
      },
      "source": [
        "## Prediction & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g8BbtDtFlNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/Colab Notebooks/snow_grooming/models/final_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4uaUxZenmyV",
        "colab_type": "text"
      },
      "source": [
        "##### Pick an image from the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvzKpf5sE_Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img_idx = 424"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5PRka7wnpXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pick one image from the test set\n",
        "img, _ = dataset_test[test_img_idx]\n",
        "\n",
        "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOG_oLCnExWF",
        "colab_type": "text"
      },
      "source": [
        "##### Make a boundary box prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sth6vmXnxrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_boundary_box_prediction(image_no_box):\n",
        "# put the model in evaluation mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      prediction = model([image_no_box.to(device)])\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzq1s9DKqNbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_example = make_boundary_box_prediction(img)\n",
        "predict_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boAukV5KE3DY",
        "colab_type": "text"
      },
      "source": [
        "##### Define function for drawing boundary box."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3IkDZpd05T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_lookup_table = {\n",
        "    1: (obj_class_labels[0], (255, 0, 0)),\n",
        "    2: (obj_class_labels[1], (0, 255, 0)),\n",
        "    3: (obj_class_labels[2], (255, 255, 0)),\n",
        "}\n",
        "\n",
        "def draw_all_boundary_boxes(image_path, prediction, threshold=0.5):\n",
        "    # get boundary boxes, scores, and labels from prediction\n",
        "    boxes = prediction[0]['boxes'].tolist()\n",
        "    scores = prediction[0]['scores'].tolist()\n",
        "    class_labels = prediction[0]['labels'].tolist()    \n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    # im is a PIL Image object\n",
        "    #im_arr = np.asarray(image)\n",
        "    for box, score, label in zip(boxes, scores, class_labels):\n",
        "      # convert rgb array to opencv's bgr format\n",
        "      #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "      if score < threshold:\n",
        "        continue\n",
        "      x1 = int(box[0])\n",
        "      y1 = int(box[3])\n",
        "      x2 = int(box[2])\n",
        "      y2 = int(box[1])\n",
        "      # pts1 and pts2 are the upper left and bottom right coordinates of the rectangle\n",
        "      cv2.rectangle(image, (x1, y1), (x2, y2), class_lookup_table[label][1], 3)\n",
        "      obj_label = 'pole' if class_lookup_table[label][0] == 'street light' else class_lookup_table[label][0]\n",
        "      cv2.putText(image, obj_label, (x1, y2-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, class_lookup_table[label][1], 2)\n",
        "    #im_arr = cv2.cvtColor(im_arr_bgr, cv2.COLOR_BGR2RGB)\n",
        "    #Image.fromarray(image)\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-T9mGhB-yWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img_idx_abs = test_idx[test_img_idx]\n",
        "path = dataset.imgs[test_img_idx_abs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SiiFG4Mz7y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = draw_all_boundary_boxes(path, predict_example)\n",
        "Image.fromarray(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubzv9i5CJFcH",
        "colab_type": "text"
      },
      "source": [
        "## Demo\n",
        "\n",
        "Demo on ski resort video footage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaD2CBc1MuNF",
        "colab_type": "text"
      },
      "source": [
        "##### Download video from YouTube.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wHxyTtQJLmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#video_url = \"https://www.youtube.com/watch?v=3tg_DOaUZ4Y\"\n",
        "video_url = \"https://www.youtube.com/watch?v=LKBQ0J-RUF8\"\n",
        "video_quality = 1080 \n",
        "only_video = True \n",
        "do_trim = False \n",
        "start = \"00:28:16\" \n",
        "end = \"00:28:46\"\n",
        "#output_file = 'pb600_winchcat_full.mp4'\n",
        "output_file = 'groomer.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFvQuiSGvk3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yt_d = Downloader(video_url, output_file, quality=video_quality, only_vid=only_video)\n",
        "yt_d.download()\n",
        "\n",
        "if do_trim:\n",
        "  yt_d.trim(start, end, delete_original=False)\n",
        "  os.rename('downloaded_vid_trimmed.mp4', 'downloaded_vid.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "low_a28Xtope",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in os.listdir():\n",
        "  if 'frame' in f:\n",
        "    os.remove(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mMPXxprMsdy",
        "colab_type": "text"
      },
      "source": [
        "##### Split video into frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G3AoKpFMy0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cap = cv2.VideoCapture('pb600_winchcat_full.mp4')\n",
        "cap = cv2.VideoCapture('groomer.mp4')\n",
        "i=0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('frame'+str(i)+'.jpg',frame)\n",
        "    i+=1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(f'{i + 1} Frames Created.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Db4JLxPYeCS",
        "colab_type": "text"
      },
      "source": [
        "##### Draw boundary boxes on each frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUIb7aV1NNEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx in range(i):\n",
        "  if idx % 100 == 0:\n",
        "    print(f'Making boundary box predictions ({idx}/{i})...')\n",
        "  # load image\n",
        "  img_frame = Image.open(f'frame{idx}.jpg').convert(\"RGB\")\n",
        "  transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "  # make prediction\n",
        "  prediction = make_boundary_box_prediction(transforms(img_frame))\n",
        "\n",
        "  # draw box\n",
        "  img_frame = draw_all_boundary_boxes(f'frame{idx}.jpg', prediction, threshold=0.5) \n",
        "\n",
        "  # resave image\n",
        "  cv2.imwrite(f'frame{idx}.jpg', img_frame)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDq0ATJ019cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image.open('frame4900.jpg').convert(\"RGB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJeFBFLIbM1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_frames_to_video(num_frames,path_out,fps):\n",
        "    frame_array = []\n",
        "    files = [f'frame{idx}.jpg' for idx in range(num_frames)][2000:5000]\n",
        " \n",
        "    #for sorting the file names properly\n",
        "    #files.sort(key = lambda x: int(x[5:-4]))\n",
        "    for f, filename in enumerate(files):\n",
        "        if f % 100 == 0:\n",
        "            print(f'Processing frame ({f}/{len(files)})...')\n",
        "        try:\n",
        "          #reading each files\n",
        "          img = cv2.imread(filename)\n",
        "          height, width, layers = img.shape\n",
        "          size = (width,height)\n",
        "          #inserting the frames into an image array\n",
        "          frame_array.append(img)\n",
        "        except AttributeError:\n",
        "          continue\n",
        " \n",
        "    out = cv2.VideoWriter(path_out,cv2.VideoWriter_fourcc(*'MJPG'), fps, size)\n",
        " \n",
        "    for i in range(len(frame_array)):\n",
        "        # writing to a image array\n",
        "        out.write(frame_array[i])\n",
        "    out.release()\n",
        "\n",
        "convert_frames_to_video(i + 1, root_dir + '/groomer_boxes.mp4', fps=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARO60WKSdbEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}